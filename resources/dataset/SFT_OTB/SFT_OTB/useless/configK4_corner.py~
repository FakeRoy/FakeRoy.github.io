'''
for recurrent shape regression
runL2.py
'''

import os,sys,pdb
import numpy as np
import tensorflow as tf

from Logger import *
from utis import *
from funs_trackingK4_corner import *

## vgg
from vgg_utis import vgg_process_images, vgg_resize_maps
import vgg19_tf
## graph
from graph import grid_graph, fea_graph,laplacian
## cgcnn
#from models import cgcnn
#from perf import fit, evaluate
from models import graphtracker# import GTTr, GTTe

#########################
##### gpu parameter #####
#########################

gpu_id = '/gpu:0'
config = tf.ConfigProto(log_device_placement=True)
config.gpu_options.allow_growth = True


#########################
#### data params ########
#########################

#data_path = r'/data/cyy/Data/CVPR2013Bechmark_Color/'
data_path = r'/data/cyy/Data/bench1/'
#cache_path = r'/home/caiyouyi/cyy/Results/gcnntracker_feasz_K0.5'
cache_path = r'/data/cyy/Results/gcnntrackerK4_corner2.4_swo_all'
if not os.path.isdir(cache_path):
    os.mkdir(cache_path)
pstr = 'gcnn'

##

start_sample = 0#97
end_sample = 97#-1
step_sample = 1#-1
idx_fdrs = np.arange(start_sample,end_sample,step_sample)
#idx_fdrs=[0]
#idx_fdrs=[0,1,2,3,4,5,6,7,8,9,10,11]
#idx_fdrs = [50,57,60,6,63,71,73,77,79,80,84,85,91,92,96,97]
#idx_fdrs.reverse()
print("{}".format(idx_fdrs))

####
padding = {'large':1,'height':0.4,'generic':2} # 25~50: 2.5 others 2.2
cell_size0 = 4  ##
batch_size = 1 # fixed
max_win2 = 1600
min_win2 = 1600
fea_sz = np.asarray([57,57])
#########################
####### VGG Model #######
#########################

vgg_model_path = '/data/cyy/Data/Model/vgg19.npy'
vgg_batch_size = 1
vgg_out_layers = np.asarray((10,11,12,14,15,16))


vgg_is_lrn = False

## image processing params for vgg
img_param = {}
img_param['interp_tool'] = 'misc' # misc or skimage
img_param['interp'] = 'bilinear'
img_param['normal_hw'] = (224,224)
img_param['normal_type'] = 'keep_all_content'

##################################
###### graph parameters ##########
##################################

gh1 = {'height_width':None,'number_edges':4,'metric':'euclidean','normalized_laplacian': True}

#gh2 = {'height_width':None,'number_edges':0.1,'metric':'euclidean','normalized_laplacian': True}


################################# gcnn paramters #################
'''
nn = {}
#nn['dir_name']      = cache_path #'/data/cuizhen/Results/mnist'
nn['num_epochs']    = 500 
nn['batch_size']    = 1
nn['decay_step']   = 100 # mnist.train.num_examples/nn['batch_size']
nn['eval_frequency']= 0 # 30*nn['num_epochs']
nn['brelu']         = None #'b1relu'
#nn['pool']          = 'mpool1'
#C    = max(mnist.train.labels) + 1

nn['regularization'] = 5e-4
nn['dropout']        = 0.5
nn['learning_rate']  = 0.02
nn['decay_rate']     = 0.95
nn['momentum']       = 0.9

nn['F'] = [1] # signal lengths of each layer
nn['K'] = [25] # poly orders
nn['p'] = [1] # pooling size, one element at least
nn['M'] = [] # hidden numbers of last layers

nn['filter'] = 'chebyshev5'
'''
#################################################################

#### pca params
pca_is_mean = True
pca_is_norm = False
pca_energy = 100
####
nn_p = 6
#nn_K = 20
nn_gamma = 1.0

####################### cf params ###############################
#search_scale = np.asarray([1,0.985,0.99,0.995,1.005,1.01,1.015,1.02,0.98],dtype=np.float32)
search_scale = fun_get_search_scale()

kernel_sigma = 0.5
kernel_type = 'linear'
kernel_gamma = 1 #1.e-6
update_factor = 0.01 # Jogging learning 0.005, others 0.015
cf_nframe_update = 1
weight_update_factor = 0.01
